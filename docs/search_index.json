[
["index.html", "W201 Portfolio Welcome! About the author", " W201 Portfolio Weixin Wu MIDS Spring 2018 Welcome! Figure .: Hello World! Welcome to Angela’s MIDS W201 Portfolio! Inside you can find some cool data science ideas that help businesses solve existing problems as well as make better decisions. Check it out below to learn more! Figure .: Welcome Message Abstract: Battle Insurance Fraud Insurance fraud has been a long lasting problem that costs the insurance industry billions of dollars every year. By better identifying these claims, an insurer can gain a competitive advantage. Analyzing the phone calls between claimants and claims adjusters using text mining and data science techniques can be a practical and efficient way to detect insurance fraud. Abstract: Data Driven Solution for Movie Rentals Family Video is one of the few remaining brick and mortar movie rental stores. From time to time, Family Video experiences inadequate inventory for some movies while excess inventory for others. My data driven solution can help Family Video fully utilize their data and easily accessible movie characteristics to optimize their inventory management and increase revenue. About the author Weixin (Angela) Wu is an actuarial statistician working in an insurance sector. She graduated from University of Illinois at Urbana-Champaign, with a double major in actuarial science and statistics. After attaining her fellowship from the Casualty Actuarial Society, she found new passion in life - data science. She wants to expand her career as a statistician and learn more about data storage and structure in a big data world. Currently she is pursuing a master’s in information and data science from University of California, Berkeley. Updated: 2018-03-13 "],
["Insurance-Fraud.html", "1 Battle Insurance Fraud with Text Mining and Data Science 1.1 Insurance Fraud: Issues and Challenges 1.2 Detect Insurance Fraud with ALL the Information You’ve Got On the Fly 1.3 Improvements Over Existing Fraud Detection Techniques", " 1 Battle Insurance Fraud with Text Mining and Data Science Abstract Insurance fraud has been a long lasting problem that costs the insurance industry billions of dollars every year. By better identifying these claims, an insurer can gain a competitive advantage. Analyzing the phone calls between claimants and claims adjusters using text mining and data science techniques can be a practical and efficient way to detect insurance fraud. Keywords insurance, fraud, solution, real-time, text mining, data science 1.1 Insurance Fraud: Issues and Challenges According to the latest report from Insurance Information Institute, property/casualty insurance fraud costs insurers about $34 billion per year, which is about 10% of the industry’s incurred losses and loss adjustment expenses (“Facts + Statistics: Industry Overview III” 2018). Any insurer who can accurately identify fraudulent claims will be able to eliminate fraudulent payments and reduce the total cost of insurance. Correspondingly, the premium charged to an average policyholder will be lowered considerably, gaining a competitive advantage for the company. Currently, fraud detection specialists are hired to review claim files and cross-reference with Insurance Services Office (ISO) data and National Insurance Crime Bureau (NICB) alerts in order to determine fraudulent claims. This process is very manual and time consuming. In addition, statisticians are tasked with building statistical models to identify common characteristics of fraud. Unfortunately, only a limited number of claims attributes are inputted in the database by claims adjusters, which are then available for modeling. As a result, those traditional models only utilized a fraction of claims information and have high false positives and false negatives. Up until now, we lack efficient and accurate ways to detect insurance fraud. Analyzing the phone calls between claimants and claims adjusters using text mining and data science techniques can be a practical and efficient way to detect insurance fraud. 1.2 Detect Insurance Fraud with ALL the Information You’ve Got On the Fly The phone calls between claimants and claims adjusters have been monitored and recorded by insurers for quality and training purposes for many years now. These phone calls are the primary communication between claimants and insurers, which are readily available for analysis. We should fully utilize information extracted from phone calls in real-time to ensure the validity of claims. The conversation between claimants and claims adjusters should be automatically converted to text and stored in the corresponding claim file. Text mining techniques should be applied in real-time to structure the input text (i.e., the conversation) and seek out key words. The key words should be automatically compared against credible sources to confirm the validity of claimants’ statements. For example, if the claimant mentioned weather, his/her statement should be verified against the weather source. As another example, if the claimant mentioned police, an automatic request for police report should be submitted with relevant driver information. Upon receival of filed police report, his/her statement should be cross-examined for any disparity. Using structured text can also facilitate the comparison between this claimant’s story and other fraud cases previously identified in the database to find resemblances. This is especially helpful in targeting organized fraud activities. In addition, Sentiment analysis should be performed to identify unusual emotions/tones and look for rehearsed responses. If prior conversations exist, the current conversation should be compared against prior conversations to discover inconsistencies in claimants’ statements. The results of text analyses above should be fed into a neural network model to produce a suspicious claim indicator with three levels of severities (mildly suspicious, highly suspicious and fraud detected). The suspicious claim indicator is continuously being updated as the conversation goes on. If a claim is marked as highly suspicious, the claim adjuster is alerted and prompted to ask additional questions. Claims adjusters are encouraged to provide feedback to the model based on their experience and intuition. Their feedback, weighted based on their historical performance and years of experience, is another important input to the neural network model. With thousands of claims being handled every day, text analyses and neural network models can be fine-tuned on the fly and eventually evolve into a system of robust models that can help insurers accurately detect fraudulent claims. 1.3 Improvements Over Existing Fraud Detection Techniques The proposed solution utilizes text mining and deep learning techniques to automate the fraud detection process, which is more efficient than relying on the manual work conducted by fraud detection specialists. It is also more predictive than traditional statistical models because it incorporates the entire conversation between claimants and claims adjusters into the analyses rather than just using the claim characteristics summarized by claims adjusters. In addition, statisticians work independently from the front-line claims adjusters, and as a result, there is a significant delay in determining fraud and lack of means to request more information. Under the proposed solution, near-instantaneous feedback from the model guides claims adjusters in gathering additional information that could lead to determination of fraudulent claims. However, one potential drawback of using real-time analyses and feedback is that the claim service time may be lengthened if follow-up questions are indicated by the model. This could negatively impact our customer satisfaction in claim handling experience. Hopefully, with ever-improving models, the false positive rates can be minimized, limiting time spent on unnecessary inquiries. Bibliography "],
["Movie-Rentals.html", "2 Now Showing: Data Driven Solution for Movie Rentals 2.1 Family Video, We Have a Problem 2.2 Lights, Camera, Action! 2.3 Two Thumbs Up", " 2 Now Showing: Data Driven Solution for Movie Rentals Abstract Family Video is one of the few remaining brick and mortar movie rental stores. From time to time, Family Video experiences inadequate inventory for some movies while excess inventory for others. My data driven solution can help Family Video fully utilize their data and easily accessible movie characteristics to optimize their inventory management and increase revenue. Keywords Family Video, movie rentals, inventory management, data driven model 2.1 Family Video, We Have a Problem Family Video owner, you are one of the few remaining brick and mortar movie rental stores and your rental prices are very competitive compared to online streaming websites. That’s why I have been your loyal customer for many years. However, from time to time I get disappointed when every copy of the movie I wanted to rent is checked out and you can’t give me an estimate when it will be available again. So I end up looking for other, usually more expensive, rental options. At the same time, I notice that other movies have dozens of copies available on the shelf. As your loyal customer and a data scientist, I would like to offer a data driven solution that optimizes your inventory management and revenue. 2.2 Lights, Camera, Action! Currently, there are at least two types of internal data available to you, one is customer transactional data and the other is inventory data. The customer transactional data details customer names, phone numbers, email addresses, checked out movies, check-out dates, intended return dates, actual return dates, etc. Inventory data contains a list of movies offered and the total number of copies ordered for each movie. You can bridge those two datasets together to find out the historical demand for each movie over time. Below is an illustration of the summarized daily longitudinal demand data for a particular movie. In this example, the number of checked out copies is equal to the total inventory level on Days 1, 2, 5, 8, and 9. Those data points are censored and thus the true demand is unknown. In other words, there was inventory deficiency on those days. The next step is to merge your longitudinal demand data with movie characteristics, such as genre, leading actors/actresses, director, box office sales, and audience rating. Tobit censored regression models (McDonald and Moffitt 1980) can be used to build the initial demand model using historical demand as the target and movie characteristics as regressors. Random survival forests (Ishwaran et al. 2008) can be used to forecast demand decay rates, varying by the initial demand projection. The combination of these two models will give you a reasonable prediction of rental demand over time. You should also sell off excess copies as early as possible because the longer you wait, the lower the sale price you will get due to lower demand. At the same time, you need to keep enough copies so that unanticipated variation in demand can be satisfied the vast majority of the time. I would recommend keeping the number of copies at the upper confidence limit of projected demand and selling off the rest. Last but not least, optimization algorithms can be applied to determine the optimal number of copies you should order that will maximize the sum of rental revenue and sale revenue net of purchase cost for each movie. As new movies release every week, you can repeatedly assess the performance of the demand model as well as the optimization strategy. You can continue to refine the model by tweaking different hyperparameters as well as incorporating new data. 2.3 Two Thumbs Up By carrying out my data driven solution, you will be able to better anticipate future rental demand and plan inventory accordingly. This enables you to satisfy your customers’ needs as much as possible so that they are less likely to seek out other rental options. In the event of shortage, the model allows you to provide an estimate to the customer when a particular movie will return in stock. Customers will feel some level of assurance that was not present before, and as a result they are more inclined to come back. The model also recommends a sale schedule for excess copies. This will free up shelf space and generate additional revenue. The additional room and capital can then be used for upcoming releases and the process begins anew. Most amazingly, the model is able to address all those customer pain points while optimizing revenue. One shortcoming of this model is that it cannot predict shock demand due to special events. For example, during Oscar season, demand for Oscar nominated movies may increase dramatically as customers wish to view those movies for the first or second time. The model will have trouble extrapolating demand out for these movies, resulting in the same poor customer experience we have today. Given this happens for a limited subset of movies, this negative will not outweigh the positive benefits mentioned earlier. Bibliography "],
["bibliography.html", "Bibliography", " Bibliography "]
]
